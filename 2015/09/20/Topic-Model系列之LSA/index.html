<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="description"><meta name="viewport" content="width=device-width, initial-scale=1"><title>Zhengwen Li</title><link rel="short icon" href="/favicon.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fonts/iconfont/iconfont.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,600|Roboto Mono"><!-- baidu analytics--><script type="text/javascript">var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?9e0cbea7d3319c6c94c71dfb93c151b8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><!-- google analytics--><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-74273646-1', 'auto');
ga('send', 'pageview');</script></head><body><div id="main"><header><a href="/." class="logo">Zhengwen Li</a><ul class="nav"><li class="nav-link"><a href="/" target="_self">Home</a></li><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/tags/" target="_self">Tags</a></li><li class="nav-link"><a href="/about/" target="_self">About</a></li></ul></header><section id="container"><article class="post"><h1 class="post-title">Topic Model系列之LSA</h1><span class="post-time">2015年9月20日</span><div class="post-content"><p>主题模型(Topic Model)是目前文本建模领域的重要模型。这是一个模型思想非常simple，但是结果却非常reasonable的模型，在抽取文本的语义和挖掘数据的隐藏结构方面，具有非常好的效果。正是因为这些特点，使得Topic Model变得非常流行，甚至可以被认为是一个标配的文本分析模型。各大公司乐于使用Topic Model去完成一些机器学习的工作，比如在门户网站的话题检测，广告系统的用户画像等，高校的老师也乐于让学生由Topic Model入手，借助它模型简单，推导复杂，而代码实现简单的特点，帮助学生进入到机器学习领域（说的就是我啦，哈哈哈）。这篇文章作为我的第一篇博文，也是第一篇介绍Topic Model的文章，将首先向大家介绍一下潜在语义分析模型（Latent Semantic Analysis/Indexing）。</p>
<h3 id="潜在语义分析(LSA)">潜在语义分析(LSA)</h3><p>　　LSA(Latent Semantic Analysis)应该是第一个非严格意义下的Topic Model。说它是一个Topic Model是因为它在一定程度上也能够抽取出文本的潜在语义，并且对后面的pLSA的提出有直接的影响。说它不是一个严格意义上的Topic Model是因为它的产生，并不是用来抽取文本潜在语义信息的，而是用来解决搜索引擎里面存在的同义词和多义词的问题。<br>　　搜索引擎一般会先在后台建立词语-文档的倒排索引，然后通过分析query，得到一些关键字，在用这些关键字到这个建好的倒排结构里去检索文档，然后做布尔运算，最后得到文档的初始列表。同义词的问题可能会因为关键字不匹配的问题，没有能够检索出关联性强的文档，多义词的问题则可能会因为一词多意的问题，使得返回的文档是非相关的文档。画个图最能够表达这个意思了。<br>　　同义词问题的原因在于，我们使用了表层词语来represent query的意图。但是仅仅使用表层词语来represent意图，在搜索引擎里显然是不够的，因为词语在计算机里只是字符串，并不能够表达意图，两个不同的字符串，有可能表达的是相同的意图，search和index是两个不同的词语，但是它们却表达相同的意图。那么，如何解决这个问题呢？一个很直观的想法就是，假如意图能够计算相似度，那么意图越相似的词语，相似度越大。为了能够计算相似度，就必须让词语落在相同的空间，然后空间上坐标越近的两个词语，它们表达的意图就越相似。问题现在变成了如何让词语落在这个意图空间，并且保证，意图越相似，两个词语在这个空间中的坐标就越接近。能够实现这个设想的方法是利用promixity models。LSA利用了其中的factor-analytic方法，准确地说，是奇异值分解方法（SVD）。</p>
<h3 id="奇异值分解">奇异值分解</h3><p>$h(x) = \theta_0 + \theta_1 x$)</p>
</div></article><div class="tags"><a href="/tag/Topic-Model-LSA/">Topic Model, LSA</a></div><div class="paginator"><a href="/2016/06/25/variational-inference/" class="prev"><i class="fa fa-chevron-left"></i><span> Prev</span></a><a href="/2015/09/13/hello-world/" class="next"><span>Next</span><i class="fa fa-chevron-right"></i></a></div><section id="comments"><div id="disqus_thread"></div></section><script type="text/javascript">(function() {
var d = document, s = d.createElement('script');

s.src = '//zwli.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script></section><footer><div class="copyright"><p><span class="heart"><i class="fa fa-heart"></i></span><span class="author">Zhengwen Li</span></p><p class="theme">Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p></div><label id="back2top"><i class="fa fa-chevron-up"></i></label><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script></footer></div></body><script src="/js/back2top.js"></script></html>